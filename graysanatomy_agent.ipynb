{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMIy9J+yjLOe+dZDhS9Cppg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/usmanakhter/graysanatomy_agent/blob/main/graysanatomy_agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# -------------------------------\n",
        "# Step 0: Install dependencies\n",
        "# -------------------------------\n",
        "!pip install --quiet langchain sentence-transformers transformers gradio faiss-cpu langchain_huggingface langchain-community"
      ],
      "metadata": {
        "id": "l7v8s426G619"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kQAVwWPvFHlO"
      },
      "outputs": [],
      "source": [
        "# =========================================\n",
        "# Gray's Anatomy QA - Fast Vector Store (GPU + Batched)\n",
        "# =========================================\n",
        "\n",
        "# Step 0: Install dependencies\n",
        "!pip install --quiet langchain sentence-transformers transformers gradio faiss-cpu\n",
        "\n",
        "# Step 1: Download Gray's Anatomy\n",
        "import requests\n",
        "import os\n",
        "\n",
        "filepath = \"grays_anatomy.txt\"\n",
        "if not os.path.exists(filepath):\n",
        "    url = \"https://archive.org/stream/anatomyofhumanbo1918gray/anatomyofhumanbo1918gray_djvu.txt\"\n",
        "    response = requests.get(url)\n",
        "    with open(filepath, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(response.text)\n",
        "    print(\"‚úì Gray's Anatomy downloaded!\")\n",
        "else:\n",
        "    print(\"‚úì Gray's Anatomy already exists!\")\n",
        "\n",
        "# Step 2: Load and split text\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "loader = TextLoader(filepath, encoding=\"utf-8\")\n",
        "documents = loader.load()\n",
        "\n",
        "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "chunks = splitter.split_documents(documents)\n",
        "print(f\"‚úì Text split into {len(chunks)} chunks\")\n",
        "\n",
        "# Step 3: Create embeddings (GPU + batched)\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\", device=device)\n",
        "\n",
        "batch_size = 64  # Adjust if GPU memory is low\n",
        "embeddings_list = []\n",
        "\n",
        "for i in range(0, len(chunks), batch_size):\n",
        "    batch_texts = [c.page_content for c in chunks[i:i+batch_size]]\n",
        "    batch_embeddings = model.encode(batch_texts, convert_to_numpy=True, batch_size=batch_size, show_progress_bar=True)\n",
        "    embeddings_list.append(batch_embeddings)\n",
        "\n",
        "embeddings = np.vstack(embeddings_list)\n",
        "print(f\"‚úì Created embeddings: shape = {embeddings.shape}\")\n",
        "\n",
        "# Step 4: Build FAISS vector store\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "# Wrap embeddings in HuggingFaceEmbeddings (for LangChain compatibility)\n",
        "hf_embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "vectorstore = FAISS.from_documents(chunks, hf_embeddings)\n",
        "vectorstore.save_local(\"grays_anatomy_vectorstore\")\n",
        "print(\"‚úì FAISS vector store created and saved!\")\n",
        "\n",
        "# Step 5: Optional - reload vector store later\n",
        "# vectorstore = FAISS.load_local(\"grays_anatomy_vectorstore\", hf_embeddings)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================\n",
        "# Gray's Anatomy AI - Embeddings-Only Gradio UI\n",
        "# =========================================\n",
        "\n",
        "# 1Ô∏è‚É£ Install dependencies (if not already)\n",
        "!pip install --quiet langchain sentence-transformers gradio faiss-cpu\n",
        "\n",
        "# 2Ô∏è‚É£ Load FAISS vector store\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "hf_embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "vectorstore = FAISS.load_local(\n",
        "    \"grays_anatomy_vectorstore\",\n",
        "    hf_embeddings,\n",
        "    allow_dangerous_deserialization=True  # safe because we built it ourselves\n",
        ")\n",
        "\n",
        "# 3Ô∏è‚É£ Define embeddings-only QA function\n",
        "def answer_question_no_llm(question, k=4):\n",
        "    docs = vectorstore.similarity_search(question, k=k)\n",
        "    answer_text = \"\\n\\n\".join([d.page_content for d in docs])\n",
        "    return answer_text[:2000]  # truncate for display\n",
        "\n",
        "# 4Ô∏è‚É£ Define Gradio chat callback\n",
        "def chat_fn(question, chat_history):\n",
        "    answer = answer_question_no_llm(question)\n",
        "    chat_history.append((question, answer))\n",
        "    return \"\", chat_history\n",
        "\n",
        "# 5Ô∏è‚É£ Build Gradio UI\n",
        "import gradio as gr\n",
        "\n",
        "with gr.Blocks(theme=gr.themes.Soft(), title=\"Gray's Anatomy AI\") as demo:\n",
        "    gr.Markdown(\"# üß† Gray's Anatomy FAQ Agent\\nAsk questions about human anatomy based on Gray's Anatomy (1918).\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=2):\n",
        "            chatbot = gr.Chatbot(height=500, label=\"Conversation\")\n",
        "            question_input = gr.Textbox(\n",
        "                placeholder=\"Ask about anatomy...\",\n",
        "                label=\"Your Question\",\n",
        "                lines=2\n",
        "            )\n",
        "            submit_btn = gr.Button(\"Ask\", variant=\"primary\")\n",
        "            clear_btn = gr.Button(\"Clear Conversation\")\n",
        "\n",
        "        with gr.Column(scale=1):\n",
        "            gr.Markdown(\"### üí° Example Questions\")\n",
        "            examples = [\n",
        "                \"What are the main bones of the skull?\",\n",
        "                \"Describe the structure of the heart\",\n",
        "                \"What muscles are involved in breathing?\",\n",
        "                \"Explain the layers of the skin\",\n",
        "                \"What is the function of the cerebellum?\",\n",
        "                \"Describe the structure of a long bone\",\n",
        "                \"What are the parts of the digestive system?\",\n",
        "                \"Explain the vertebral column\"\n",
        "            ]\n",
        "            for ex in examples:\n",
        "                btn = gr.Button(ex, size=\"sm\")\n",
        "                btn.click(lambda x=ex: x, outputs=question_input)\n",
        "\n",
        "    # 6Ô∏è‚É£ Wire events\n",
        "    submit_btn.click(chat_fn, inputs=[question_input, chatbot], outputs=[question_input, chatbot])\n",
        "    question_input.submit(chat_fn, inputs=[question_input, chatbot], outputs=[question_input, chatbot])\n",
        "    clear_btn.click(lambda: (\"\", []), None, chatbot)\n",
        "\n",
        "# 7Ô∏è‚É£ Launch\n",
        "demo.launch(share=True)\n"
      ],
      "metadata": {
        "id": "MJwoAuRrJWg7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}